
# tests/conftest.py
# ==================================================
"""Pytest configuration for asyncio testing."""

import pytest


def pytest_addoption(parser):
    """Add pytest command line options."""
    parser.addini("asyncio_mode", "default mode for async fixtures", default="strict")

# tests/__init__.py
# ==================================================

# bee_agent/__init__.py
# ==================================================
from .agents import BaseAgent, BeeAgent

from .llms import BaseLLM, LLM, Prompt, AgentInput

from .tools import WeatherTool, Tool

from .memory import BaseMemory, UnconstrainedMemory, ReadOnlyMemory, TokenMemory

from .memory.message import BaseMessage

from .memory.serializable import Serializable

from .utils.roles import Role

__all__ = [
    "BaseAgent",
    "BeeAgent",
    "BaseLLM",
    "LLM",
    "Prompt",
    "AgentInput",
    "WeatherTool",
    "Tool",
    "BaseMemory",
    "UnconstrainedMemory",
    "ReadOnlyMemory",
    "TokenMemory",
    "BaseMessage",
    "Role",
    "Serializable",
]

# dev_tools/scripts.py
# ==================================================
import subprocess
import sys


def lint():
    try:
        subprocess.run(["black", "."], check=True)
        subprocess.run(["ruff", "check", "."], check=True)
    except subprocess.CalledProcessError:
        sys.exit(1)


def commit():
    try:
        if len(sys.argv) < 2:
            print("Error: Please provide a commit message")
            print('Usage: poetry run commit "<commit message>"')
            sys.exit(1)

        commit_message = sys.argv[1]

        print("ðŸ“¦ Adding files...")
        subprocess.run(["git", "add", "--all"], check=True)

        print("ðŸ“ Committing changes...")
        subprocess.run(["git", "commit", "-s", "-m", commit_message], check=True)

        print("Successfully committed changes")

    except subprocess.CalledProcessError as e:
        print(f"Error during git operations: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Unexpected error: {e}", file=sys.stderr)
        sys.exit(1)

# tests/bee_agent/tools/test_mcp_tool.py
# ==================================================
"""Tests for the MCPTool implementation."""

import asyncio
import logging
from typing import AsyncGenerator, Sequence
from contextlib import asynccontextmanager

import pytest
import pytest_asyncio
import anyio
from mcp.server import Server
from mcp.shared.memory import create_client_server_memory_streams
from mcp.types import TextContent, ImageContent, EmbeddedResource, Tool as MCPToolInfo
from mcp.client.session import ClientSession
from bee_agent.tools import MCPTool

# Set up logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

pytestmark = pytest.mark.asyncio

# Test input schema
ab_input_schema = {
    "type": "object",
    "properties": {"a": {"type": "number"}, "b": {"type": "number"}},
    "required": ["a", "b"],
}


async def handle_list_tools():
    """Handle list tools request."""
    logger.debug("Handling list_tools request")
    try:
        tools = [
            MCPToolInfo(
                name="add",
                description="Adds two numbers",
                inputSchema=ab_input_schema,
            ),
            MCPToolInfo(
                name="multiply",
                description="Multiplies two numbers",
                inputSchema=ab_input_schema,
            ),
        ]
        logger.debug(f"Returning tools list: {tools}")
        return tools
    except Exception as e:
        logger.error(f"Error in handle_list_tools: {str(e)}")
        raise


async def handle_call_tool(
    name: str, arguments: dict
) -> Sequence[TextContent | ImageContent | EmbeddedResource]:
    """Handle tool call request."""
    logger.debug(f"Handling tool call: {name} with arguments: {arguments}")
    try:
        if name == "add":
            logger.debug(f"Executing add tool with {arguments}")
            a, b = float(arguments["a"]), float(arguments["b"])
            result = str(int(a + b))
            return [TextContent(type="text", text=result)]
        elif name == "multiply":
            logger.debug(f"Executing multiply tool with {arguments}")
            a, b = float(arguments["a"]), float(arguments["b"])
            result = str(int(a * b))
            return [TextContent(type="text", text=result)]
        else:
            raise ValueError(f"Unknown tool: {name}")
    except Exception as e:
        logger.error(f"Error in handle_call_tool: {str(e)}")
        raise


@pytest_asyncio.fixture
async def server_client():
    """Fixture that provides a server and connected client."""
    logger.debug("Starting server_client fixture")

    # Initialize server
    server = Server("test-server")
    server.list_tools()(handle_list_tools)
    server.call_tool()(handle_call_tool)
    logger.debug("Server initialized")

    # Event for server initialization and graceful shutdown
    ready_event = asyncio.Event()
    shutdown_event = asyncio.Event()

    # Create memory streams
    async with create_client_server_memory_streams() as (
        client_streams,
        server_streams,
    ):
        client_read, client_write = client_streams
        server_read, server_write = server_streams
        logger.debug("Memory streams created")

        # Create task group for server
        async def run_server():
            try:
                options = server.create_initialization_options()

                async def on_initialize():
                    # Signal server is ready
                    ready_event.set()
                    logger.debug("Server initialization complete")

                    # Wait for shutdown signal
                    await shutdown_event.wait()
                    logger.debug("Server shutdown initiated")

                options.on_initialize = on_initialize
                await server.run(server_read, server_write, options)
            except Exception as e:
                logger.error(f"Server error: {str(e)}")
                ready_event.set()  # Ensure we don't hang
                raise

        # Create client session
        async with (
            anyio.create_task_group() as tg,
            ClientSession(read_stream=client_read, write_stream=client_write) as client,
        ):
            # Start server
            tg.start_soon(run_server)
            logger.debug("Server started")

            # Wait for initialization
            try:
                async with asyncio.timeout(5):
                    await ready_event.wait()
                    logger.debug("Server ready")
            except asyncio.TimeoutError:
                logger.error("Server initialization timeout")
                raise

            yield client

            # Signal server to shut down
            shutdown_event.set()
            logger.debug("Server shutdown complete")


class TestMCPTool:
    """Test suite for MCPTool."""

    async def test_list_tools(self, server_client):
        """Test that tools can be listed correctly."""
        logger.debug("Starting test_list_tools")
        tools = await MCPTool.from_client(server_client)
        logger.debug(f"Retrieved tools: {tools}")
        assert len(tools) == 2, f"Expected 2 tools, got {len(tools)}"
        assert any(t.name == "add" for t in tools), "Add tool not found"
        assert any(t.name == "multiply" for t in tools), "Multiply tool not found"
        logger.debug("test_list_tools completed successfully")

    async def test_add_tool(self, server_client):
        """Test that add tool works correctly."""
        logger.debug("Starting test_add_tool")
        tools = await MCPTool.from_client(server_client)
        add_tool_instance = next(t for t in tools if t.name == "add")

        test_input = {"a": 2, "b": 3}
        logger.debug(f"Calling add tool with input: {test_input}")
        result = await add_tool_instance.run(test_input)
        logger.debug(f"Add tool result: {result}")
        assert result.result.content[0].text == "5"
        logger.debug("test_add_tool completed successfully")

    async def test_multiply_tool(self, server_client):
        """Test that multiply tool works correctly."""
        logger.debug("Starting test_multiply_tool")
        tools = await MCPTool.from_client(server_client)
        multiply_tool_instance = next(t for t in tools if t.name == "multiply")

        test_input = {"a": 2, "b": 3}
        logger.debug(f"Calling multiply tool with input: {test_input}")
        result = await multiply_tool_instance.run(test_input)
        logger.debug(f"Multiply tool result: {result}")
        assert result.result.content[0].text == "6"
        logger.debug("test_multiply_tool completed successfully")

# bee_agent/tools/weather.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import Literal, Optional, TypedDict
from urllib.parse import urlencode

import requests

from .tool import Tool


class WeatherLocation(TypedDict):
    name: Optional[str]
    country: Optional[str]
    language: Optional[str]
    latitude: Optional[float]
    longitude: Optional[float]


class WeatherInput(TypedDict):
    location: WeatherLocation
    start_date: Optional[str]
    end_data: Optional[str]
    temperature_unit: Optional[Literal["celsius", "fahrenheit"]] = "celsius"


class WeatherTool(Tool):
    name = "WeatherTool"
    description = "Retrieve current, past, or future weather forecasts for a location."

    def input_schema(self):
        # # TODO: remove hard code
        return '{"type":"object","properties":{"location":{"anyOf":[{"type":"object","properties":{"name":{"type":"string"},"country":{"type":"string"},"language":{"type":"string","default":"English"}},"required":["name"],"additionalProperties":false},{"type":"object","properties":{"latitude":{"type":"number"},"longitude":{"type":"number"}},"required":["latitude","longitude"],"additionalProperties":false}]},"start_date":{"type":"string","format":"date","description":"Start date for the weather forecast in the format YYYY-MM-DD (UTC)"},"end_date":{"type":"string","format":"date","description":"End date for the weather forecast in the format YYYY-MM-DD (UTC)"},"temperature_unit":{"type":"string","enum":["celsius","fahrenheit"],"default":"celsius"}},"required":["location","start_date"],"additionalProperties":false}'

    def _geocode(self, location):
        params = {"format": "json", "count": 1}
        if location.get("name"):
            params["name"] = location.get("name")
        if location.get("country"):
            params["country"] = location.get("country")
        if location.get("language"):
            params["language"] = location.get("language")
        params = urlencode(params, doseq=True)

        response = requests.get(
            f"https://geocoding-api.open-meteo.com/v1/search?${params}",
            headers={"Content-Type": "application/json", "Accept": "application/json"},
        )

        response.raise_for_status()
        results = response.json()["results"]
        return results[0]

    def get_params(self, input: WeatherInput):
        params = {
            "forecast_days": 1,
            "current": [
                "temperature_2m",
                "rain",
                "relative_humidity_2m",
                "wind_speed_10m",
            ],
            "daily": ["temperature_2m_max", "temperature_2m_min", "rain_sum"],
            "hourly": ["temperature_2m", "relative_humidity_2m", "rain"],
            "timezone": "UTC",
        }

        if input.get("location", {}).get("name"):
            geocode = self._geocode(input.get("location"))
            params["latitude"] = geocode.get("latitude")
            params["longitude"] = geocode.get("longitude")
        else:
            params["latitude"] = input.get("location", {}).get("latitude")
            params["longitude"] = input.get("location", {}).get("longitude")

        return params

    def _run(self, input: WeatherInput, options=None):
        params = urlencode(self.get_params(input), doseq=True)
        response = requests.get(
            f"https://api.open-meteo.com/v1/forecast?${params}",
            headers={"Content-Type": "application/json", "Accept": "application/json"},
        )
        response.raise_for_status()
        return response.json()

# bee_agent/tools/__init__.py
# ==================================================
from .weather import WeatherTool
from .tool import Tool
from .mcp_tools import MCPTool

__all__ = ["WeatherTool", "Tool", "MCPTool"]

# bee_agent/tools/mcp_tools.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import Dict, List, Optional, TypeVar, Any, Sequence
from dataclasses import dataclass

from bee_agent.tools import Tool
from bee_agent.utils import BeeEventEmitter
from mcp.client.session import ClientSession
from mcp.types import (
    Tool as MCPToolInfo,
    CallToolResult,
    TextContent,
    ImageContent,
    EmbeddedResource,
)

T = TypeVar("T")


@dataclass
class MCPToolInput:
    """Input configuration for MCP Tool initialization."""

    client: ClientSession
    tool: MCPToolInfo


class MCPToolOutput:
    """Output class for MCP Tool results."""

    def __init__(self, result: CallToolResult):
        self.result = result


class MCPTool(Tool[MCPToolOutput]):
    """Tool implementation for Model Context Protocol."""

    def __init__(self, client: ClientSession, tool: MCPToolInfo, **options):
        """Initialize MCPTool with client and tool configuration."""
        super().__init__(options)
        self.client = client
        self._tool = tool
        self._name = tool.name
        self._description = (
            tool.description
            or "No available description, use the tool based on its name and schema."
        )
        self.emitter = BeeEventEmitter()

    @property
    def name(self) -> str:
        return self._name

    @property
    def description(self) -> str:
        return self._description

    def input_schema(self) -> str:
        return self._tool.inputSchema

    async def _run(
        self, input_data: Any, options: Optional[Dict] = None
    ) -> MCPToolOutput:
        """Execute the tool with given input."""
        print(f"Executing tool {self.name} with input: {input_data}")  # Debug
        result = await self.client.call_tool(name=self.name, arguments=input_data)
        print(f"Tool result: {result}")  # Debug
        return MCPToolOutput(result)

    @classmethod
    async def from_client(cls, client: ClientSession) -> List["MCPTool"]:
        tools_result = await client.list_tools()
        return [cls(client=client, tool=tool) for tool in tools_result.tools]

# bee_agent/tools/tool.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod
from typing import Any, Dict, Generic, TypeVar


T = TypeVar("T")


class Tool(Generic[T], ABC):
    options: Dict[str, Any] = {}

    def __init__(self, options={}):
        self.options = options

    @property
    @abstractmethod
    def name(self):
        pass

    @property
    @abstractmethod
    def description(self):
        pass

    @abstractmethod
    def input_schema(self):
        pass

    @abstractmethod
    def _run(self, input, options=None):
        pass

    def prompt_data(self):
        return {
            "name": self.name,
            "description": self.description,
            "schema": self.input_schema(),
        }

    def run(self, input: T, options=None):
        return self._run(input, options)

# bee_agent/tools/wikipedia.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from .tool import Tool


class WikipediaTool(Tool):
    name = "Wikipedia"
    description = "Search factual and historical information, including biography, history, politics, geography, society, culture, science, technology, people, animal species, mathematics, and other subjects."

    def input_schema(self):
        # # TODO: remove hard code
        return '{"type":"object","properties":{"query":{"type":"string","format":"date","description":"Name of the wikipedia page, for example \'New York\'"}}}'

    def _run(self, input, options=None):
        pass

# bee_agent/memory/sliding_memory.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import List, Optional, Dict, Any, Callable, Union, TypedDict
from copy import copy
from dataclasses import dataclass
from .base_memory import BaseMemory
from .message import BaseMessage


class SlidingMemoryHandlers(TypedDict, total=False):
    """Type definition for SlidingMemory handlers."""

    removal_selector: Callable[
        [List[BaseMessage]], Union[BaseMessage, List[BaseMessage]]
    ]


@dataclass
class SlidingMemoryConfig:
    """Configuration for SlidingMemory."""

    size: int
    handlers: Optional[SlidingMemoryHandlers] = None


class SlidingMemory(BaseMemory):
    """Memory implementation using a sliding window approach."""

    def __init__(self, config: SlidingMemoryConfig):
        """Initialize SlidingMemory with given configuration.

        Args:
            config: Configuration including window size and optional handlers
        """
        self._messages: List[BaseMessage] = []
        self.config = config

        # Set default handlers if not provided
        if self.config.handlers is None:
            self.config.handlers = {}

        # Set default removal selector if not provided
        if "removal_selector" not in self.config.handlers:
            self.config.handlers["removal_selector"] = lambda messages: [messages[0]]

    @property
    def messages(self) -> List[BaseMessage]:
        """Get list of stored messages."""
        return self._messages

    def _is_overflow(self, additional_messages: int = 1) -> bool:
        """Check if adding messages would cause overflow."""
        return len(self._messages) + additional_messages > self.config.size

    def _ensure_range(self, index: int, min_val: int, max_val: int) -> int:
        """Ensure index is within the specified range."""
        return max(min_val, min(index, max_val))

    async def add(self, message: BaseMessage, index: Optional[int] = None) -> None:
        """Add a message to memory, managing window size.

        Args:
            message: Message to add
            index: Optional position to insert message

        Raises:
            MemoryFatalError: If removal selector fails to prevent overflow
        """
        # Check for overflow
        if self._is_overflow():
            # Get messages to remove using removal selector
            to_remove = self.config.handlers["removal_selector"](self._messages)
            if not isinstance(to_remove, list):
                to_remove = [to_remove]

            # Remove selected messages
            for msg in to_remove:
                try:
                    msg_index = self._messages.index(msg)
                    self._messages.pop(msg_index)
                except ValueError:
                    raise MemoryError(
                        "Cannot delete non existing message.",
                        context={"message": msg, "messages": self._messages},
                    )

            # Check if we still have overflow
            if self._is_overflow():
                raise MemoryError(
                    "Custom memory removalSelector did not return enough messages. Memory overflow has occurred."
                )

        # Add new message
        if index is None:
            index = len(self._messages)
        index = self._ensure_range(index, 0, len(self._messages))
        self._messages.insert(index, message)

    async def delete(self, message: BaseMessage) -> bool:
        """Delete a message from memory.

        Args:
            message: Message to delete

        Returns:
            bool: True if message was found and deleted
        """
        try:
            self._messages.remove(message)
            return True
        except ValueError:
            return False

    def reset(self) -> None:
        """Clear all messages from memory."""
        self._messages.clear()

    def create_snapshot(self) -> Dict[str, Any]:
        """Create a serializable snapshot of current state."""
        return {
            "config": {"size": self.config.size, "handlers": self.config.handlers},
            "messages": copy(self._messages),
        }

    def load_snapshot(self, state: Dict[str, Any]) -> None:
        """Restore state from a snapshot."""
        self.config = SlidingMemoryConfig(
            size=state["config"]["size"], handlers=state["config"]["handlers"]
        )
        self._messages = copy(state["messages"])

# bee_agent/memory/readonly_memory.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import List, Dict, Optional
from .base_memory import BaseMemory
from .message import BaseMessage


class ReadOnlyMemory(BaseMemory):
    """Read-only wrapper for a memory instance."""

    def __init__(self, source: BaseMemory):
        self.source = source

    @property
    def messages(self) -> List[BaseMessage]:
        return self.source.messages

    async def add(self, message: BaseMessage, index: Optional[int] = None) -> None:
        pass  # No-op for read-only memory

    async def delete(self, message: BaseMessage) -> bool:
        return False  # No-op for read-only memory

    def reset(self) -> None:
        pass  # No-op for read-only memory

    def create_snapshot(self) -> Dict:
        return {"source": self.source}

    def load_snapshot(self, state: Dict) -> None:
        self.source = state["source"]

    def as_read_only(self) -> "ReadOnlyMemory":
        """Return self since already read-only."""
        return self

# bee_agent/memory/base_memory.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod
from typing import List, Optional, Iterable, Any, TYPE_CHECKING

from .message import BaseMessage

if TYPE_CHECKING:
    from .readonly_memory import ReadOnlyMemory


class BaseMemory(ABC):
    """Abstract base class for all memory implementations."""

    @property
    @abstractmethod
    def messages(self) -> List[BaseMessage]:
        """Return list of stored messages."""
        pass

    @abstractmethod
    async def add(self, message: BaseMessage, index: Optional[int] = None) -> None:
        """Add a message to memory."""
        pass

    @abstractmethod
    async def delete(self, message: BaseMessage) -> bool:
        """Delete a message from memory."""
        pass

    @abstractmethod
    def reset(self) -> None:
        """Clear all messages from memory."""
        pass

    async def add_many(
        self, messages: Iterable[BaseMessage], start: Optional[int] = None
    ) -> None:
        """Add multiple messages to memory."""
        counter = 0
        for msg in messages:
            index = None if start is None else start + counter
            await self.add(msg, index)
            counter += 1

    async def delete_many(self, messages: Iterable[BaseMessage]) -> None:
        """Delete multiple messages from memory."""
        for msg in messages:
            await self.delete(msg)

    async def splice(
        self, start: int, delete_count: int, *items: BaseMessage
    ) -> List[BaseMessage]:
        """Remove and insert messages at a specific position."""
        total = len(self.messages)
        start = max(total + start, 0) if start < 0 else start
        delete_count = min(delete_count, total - start)

        deleted_items = self.messages[start : start + delete_count]
        await self.delete_many(deleted_items)
        await self.add_many(items, start)

        return deleted_items

    def is_empty(self) -> bool:
        """Check if memory is empty."""
        return len(self.messages) == 0

    def __iter__(self):
        return iter(self.messages)

    @abstractmethod
    def create_snapshot(self) -> Any:
        """Create a serializable snapshot of current state."""
        pass

    @abstractmethod
    def load_snapshot(self, state: Any) -> None:
        """Restore state from a snapshot."""
        pass

    def as_read_only(self) -> "ReadOnlyMemory":
        """Return a read-only view of this memory."""
        from .readonly_memory import (
            ReadOnlyMemory,
        )  # Import here to avoid circular import

        return ReadOnlyMemory(self)

# bee_agent/memory/sliding_cache.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import Generic, TypeVar, Optional, Dict, Any
from collections import OrderedDict
import time
from .base_cache import BaseCache
from .serializer import Serializer

T = TypeVar("T")


class SlidingCache(BaseCache[T], Generic[T]):
    """Cache implementation using a sliding window strategy."""

    def __init__(self, size: float = float("inf"), ttl: Optional[float] = None):
        """
        Initialize the sliding cache.

        Args:
            size: Maximum number of items (default: infinite)
            ttl: Time-to-live in seconds (default: None)
        """
        super().__init__()
        self._max_size = size
        self._ttl = ttl
        self._items: OrderedDict[str, tuple[T, float]] = OrderedDict()
        # Register for serialization
        self._register()

    @classmethod
    def _register(cls) -> None:
        """Register this class for serialization."""
        Serializer.register_serializable(cls)

    def _evict_expired(self) -> None:
        """Remove expired entries."""
        if self._ttl is None:
            return

        current_time = time.time()
        expired_keys = [
            key
            for key, (_, timestamp) in self._items.items()
            if current_time - timestamp > self._ttl
        ]

        for key in expired_keys:
            self._items.pop(key, None)

    def _evict_overflow(self) -> None:
        """Remove oldest entries if size limit is exceeded."""
        while len(self._items) > self._max_size:
            self._items.popitem(last=False)

    async def set(self, key: str, value: T) -> None:
        """Set a value in the cache."""
        self._evict_expired()
        self._items[key] = (value, time.time())
        self._evict_overflow()

    async def get(self, key: str) -> Optional[T]:
        """Get a value from the cache."""
        self._evict_expired()
        if key in self._items:
            value, _ = self._items[key]
            # Move to end (most recently used)
            self._items.move_to_end(key)
            return value
        return None

    async def has(self, key: str) -> bool:
        """Check if a key exists in the cache."""
        self._evict_expired()
        return key in self._items

    async def delete(self, key: str) -> bool:
        """Delete a key from the cache."""
        if key in self._items:
            del self._items[key]
            return True
        return False

    async def clear(self) -> None:
        """Clear all items from the cache."""
        self._items.clear()

    async def size(self) -> int:
        """Get the current number of items in the cache."""
        self._evict_expired()
        return len(self._items)

    async def create_snapshot(self) -> Dict[str, Any]:
        """Create a serializable snapshot of the current state."""
        self._evict_expired()
        return {
            "max_size": self._max_size,
            "ttl": self._ttl,
            "items": [(k, v[0], v[1]) for k, v in self._items.items()],
        }

    def load_snapshot(self, snapshot: Dict[str, Any]) -> None:
        """Restore state from a snapshot."""
        self._max_size = snapshot["max_size"]
        self._ttl = snapshot["ttl"]
        self._items = OrderedDict()
        for key, value, timestamp in snapshot["items"]:
            self._items[key] = (value, timestamp)

    @classmethod
    def from_snapshot(cls, snapshot: Dict[str, Any]) -> "SlidingCache[T]":
        """Create an instance from a snapshot."""
        instance = cls(
            size=snapshot.get("max_size", float("inf")), ttl=snapshot.get("ttl")
        )
        instance.load_snapshot(snapshot)
        return instance

# bee_agent/memory/unconstrained_memory.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import List, Optional, Dict
from copy import copy
from .base_memory import BaseMemory
from .message import BaseMessage


class UnconstrainedMemory(BaseMemory):
    """Simple memory implementation with no constraints."""

    def __init__(self):
        self._messages: List[BaseMessage] = []

    @property
    def messages(self) -> List[BaseMessage]:
        return self._messages

    async def add(self, message: BaseMessage, index: Optional[int] = None) -> None:
        index = (
            len(self._messages)
            if index is None
            else max(0, min(index, len(self._messages)))
        )
        self._messages.insert(index, message)

    async def delete(self, message: BaseMessage) -> bool:
        try:
            self._messages.remove(message)
            return True
        except ValueError:
            return False

    def reset(self) -> None:
        self._messages.clear()

    def create_snapshot(self) -> Dict:
        return {"messages": copy(self._messages)}

    def load_snapshot(self, state: Dict) -> None:
        self._messages = copy(state["messages"])

# bee_agent/memory/file_cache.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

import os
import aiofiles
from typing import TypeVar, Generic, Dict, Any
from dataclasses import dataclass
from functools import wraps

from .base_cache import BaseCache
from .sliding_cache import SlidingCache
from .serializer import Serializer

T = TypeVar("T")


def cache():
    """Decorator to cache method results."""

    def decorator(func):
        cache_key = f"_cache_{func.__name__}"

        @wraps(func)
        async def wrapper(self, *args, **kwargs):
            if not hasattr(self, cache_key):
                setattr(self, cache_key, await func(self, *args, **kwargs))
            return getattr(self, cache_key)

        wrapper.clear_cache = lambda self: (
            delattr(self, cache_key) if hasattr(self, cache_key) else None
        )
        return wrapper

    return decorator


@dataclass
class Input:
    """Input configuration for FileCache."""

    full_path: str


class FileCache(BaseCache[T], Generic[T]):
    """File-based cache implementation."""

    def __init__(self, input_config: Input):
        """Initialize the FileCache with the given input configuration."""
        super().__init__()
        self._input = input_config
        self._register()

    @classmethod
    def _register(cls) -> None:
        """Register the cache class."""
        Serializer.register(
            cls,
            {
                "to_plain": lambda x: x.create_snapshot(),
                "from_plain": lambda x: cls.from_snapshot(x),
            },
        )

    @property
    def source(self) -> str:
        """Get the source file path."""
        return self._input.full_path

    @classmethod
    async def from_provider(
        cls, provider: BaseCache[T], input_config: Input
    ) -> "FileCache[T]":
        """Create a new FileCache instance from a provider."""
        async with aiofiles.open(input_config.full_path, "w") as f:
            serialized = await provider.serialize()  # Await the serialization
            await f.write(serialized)
        return cls(input_config)

    @cache()
    async def _get_provider(self) -> BaseCache[T]:
        """Get the cache provider instance."""
        try:
            exists = os.path.isfile(self._input.full_path)
        except Exception:
            exists = False

        if exists:
            async with aiofiles.open(self._input.full_path, "r") as f:
                serialized = await f.read()

            deserialized = await Serializer.deserialize(serialized)
            target = deserialized["target"]
            snapshot = deserialized["snapshot"]

            Target = Serializer.get_factory(target).ref
            instance = Target.from_snapshot(snapshot)

            if not isinstance(instance, BaseCache):
                raise TypeError(
                    "Provided file does not serialize any instance of BaseCache class."
                )

            return instance
        else:
            return SlidingCache(size=float("inf"), ttl=float("inf"))

    async def reload(self) -> None:
        """Reload the cache from the file."""
        self._get_provider.clear_cache(self)
        await self._get_provider()

    async def _save(self) -> None:
        """Save the cache to the file."""
        provider = await self._get_provider()
        async with aiofiles.open(self._input.full_path, "w") as f:
            serialized = await provider.serialize()  # Await the serialization
            await f.write(serialized)

    async def size(self) -> int:
        """Get the number of items in the cache."""
        provider = await self._get_provider()
        return await provider.size()

    async def set(self, key: str, value: T) -> None:
        """Set a value in the cache."""
        provider = await self._get_provider()
        await provider.set(key, value)
        try:
            await provider.get(key)
        finally:
            await self._save()

    async def get(self, key: str) -> T:
        """Get a value from the cache."""
        provider = await self._get_provider()
        return await provider.get(key)

    async def has(self, key: str) -> bool:
        """Check if a key exists in the cache."""
        provider = await self._get_provider()
        return await provider.has(key)

    async def delete(self, key: str) -> bool:
        """Delete a key from the cache."""
        provider = await self._get_provider()
        result = await provider.delete(key)
        await self._save()
        return result

    async def clear(self) -> None:
        """Clear all items from the cache."""
        provider = await self._get_provider()
        await provider.clear()
        await self._save()

    async def create_snapshot(self) -> Dict[str, Any]:
        """Create a serializable snapshot of the current state."""
        return {
            "input": {"full_path": self._input.full_path},
            "provider": await self._get_provider(),
        }

    def load_snapshot(self, snapshot: Dict[str, Any]) -> None:
        """Restore state from a snapshot."""
        for key, value in snapshot.items():
            setattr(self, key, value)

    @classmethod
    def from_snapshot(cls, snapshot: Dict[str, Any]) -> "FileCache[T]":
        """Create an instance from a snapshot."""
        instance = cls(Input(full_path=snapshot["input"]["full_path"]))
        instance.load_snapshot(snapshot)
        return instance


if __name__ == "__main__":
    import asyncio
    import tempfile
    import os
    from pathlib import Path

    async def test_file_cache():
        try:
            # Create a temporary directory for our test cache files
            with tempfile.TemporaryDirectory() as temp_dir:
                cache_file = Path(temp_dir) / "test_cache.json"

                print("\n1. Creating and Testing Basic Cache Operations:")
                # Initialize the cache
                cache = FileCache[str](Input(str(cache_file)))

                # Test basic operations
                print("Setting values in cache...")
                await cache.set("key1", "value1")
                await cache.set("key2", "value2")

                # Verify values
                value1 = await cache.get("key1")
                value2 = await cache.get("key2")
                print(f"Retrieved values: key1={value1}, key2={value2}")

                # Check existence
                has_key = await cache.has("key1")
                print(f"Has key1: {has_key}")

                # Get cache size
                size = await cache.size()
                print(f"Cache size: {size}")

                print("\n2. Testing File Persistence:")
                # Verify file was created
                print(f"Cache file exists: {cache_file.exists()}")
                print(f"Cache file size: {cache_file.stat().st_size} bytes")

                print("\n3. Testing Delete Operation:")
                # Delete a key
                deleted = await cache.delete("key2")
                print(f"Deleted key2: {deleted}")
                has_key2 = await cache.has("key2")
                print(f"Has key2 after delete: {has_key2}")

                print("\n4. Testing Clear Operation:")
                # Clear the cache
                await cache.clear()
                size = await cache.size()
                print(f"Cache size after clear: {size}")

                print("\n5. Testing Provider Creation:")
                # Test with non-existent file
                new_file = Path(temp_dir) / "new_cache.json"
                new_cache = FileCache[str](Input(str(new_file)))
                await new_cache.set("test_key", "test_value")
                print(f"Created new cache file: {new_file.exists()}")

        except Exception as e:
            print(f"Error during test: {str(e)}")

    # Run the test
    asyncio.run(test_file_cache())

# bee_agent/memory/token_memory.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import List, Optional, Dict, Any
from copy import copy
from .base_memory import BaseMemory
from .message import BaseMessage


class TokenMemory(BaseMemory):
    """Memory implementation that respects token limits."""

    def __init__(
        self,
        llm: Any,
        max_tokens: Optional[int] = None,
        sync_threshold: float = 0.25,
        capacity_threshold: float = 0.75,
        handlers: Optional[Dict] = None,
    ):
        self._messages: List[BaseMessage] = []
        self.llm = llm
        self.max_tokens = max_tokens
        self.threshold = capacity_threshold
        self.sync_threshold = sync_threshold
        self._tokens_by_message = {}

        self.handlers = {
            "estimate": (
                handlers.get("estimate", self._default_estimate)
                if handlers
                else self._default_estimate
            ),
            "removal_selector": (
                handlers.get("removal_selector", lambda msgs: msgs[0])
                if handlers
                else lambda msgs: msgs[0]
            ),
        }

        if not 0 <= self.threshold <= 1:
            raise ValueError('"capacity_threshold" must be a number in range (0, 1)')

    @staticmethod
    def _default_estimate(msg: BaseMessage) -> int:
        return int((len(msg.role) + len(msg.text)) / 4)

    def _get_message_key(self, message: BaseMessage) -> str:
        """Generate a unique key for a message."""
        return f"{message.role}:{message.text}"

    @property
    def messages(self) -> List[BaseMessage]:
        return self._messages

    @property
    def tokens_used(self) -> int:
        return sum(
            info.get("tokens_count", 0) for info in self._tokens_by_message.values()
        )

    @property
    def is_dirty(self) -> bool:
        return any(info.get("dirty", True) for info in self._tokens_by_message.values())

    async def sync(self) -> None:
        """Synchronize token counts with LLM."""
        for msg in self._messages:
            key = self._get_message_key(msg)
            cache = self._tokens_by_message.get(key, {})
            if cache.get("dirty", True):
                try:
                    result = self.llm.tokenize([msg])
                    self._tokens_by_message[key] = {
                        "tokens_count": result["tokens_count"],
                        "dirty": False,
                    }
                except Exception as e:
                    print(f"Error tokenizing message: {str(e)}")
                    self._tokens_by_message[key] = {
                        "tokens_count": self.handlers["estimate"](msg),
                        "dirty": True,
                    }

    async def add(self, message: BaseMessage, index: Optional[int] = None) -> None:
        index = (
            len(self._messages)
            if index is None
            else max(0, min(index, len(self._messages)))
        )
        self._messages.insert(index, message)

        key = self._get_message_key(message)
        estimated_tokens = self.handlers["estimate"](message)
        self._tokens_by_message[key] = {
            "tokens_count": estimated_tokens,
            "dirty": True,
        }

        dirty_count = sum(
            1 for info in self._tokens_by_message.values() if info.get("dirty", True)
        )
        if (
            len(self._messages) > 0
            and dirty_count / len(self._messages) >= self.sync_threshold
        ):
            await self.sync()

    async def delete(self, message: BaseMessage) -> bool:
        try:
            key = self._get_message_key(message)
            self._messages.remove(message)
            self._tokens_by_message.pop(key, None)
            return True
        except ValueError:
            return False

    def reset(self) -> None:
        self._messages.clear()
        self._tokens_by_message.clear()

    def create_snapshot(self) -> Dict[str, Any]:
        return {
            "messages": copy(self._messages),
            "token_counts": copy(self._tokens_by_message),
        }

    def load_snapshot(self, state: Dict[str, Any]) -> None:
        self._messages = copy(state["messages"])
        self._tokens_by_message = copy(state["token_counts"])

# bee_agent/memory/serializable.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod
from typing import Dict, Any, Type, TypeVar, Optional, ClassVar
from copy import deepcopy

T = TypeVar("T")


class Serializable(ABC):
    """Base class for all serializable objects."""

    _registered_classes: ClassVar[Dict[str, Type["Serializable"]]] = {}

    def __init_subclass__(cls, **kwargs):
        """Automatically register subclasses when they're created."""
        super().__init_subclass__(**kwargs)
        cls._registered_classes[cls.__name__] = cls

    @classmethod
    def register(cls, aliases: Optional[list[str]] = None) -> None:
        """Register the class and any aliases for serialization."""
        cls._registered_classes[cls.__name__] = cls
        if aliases:
            for alias in aliases:
                if (
                    alias in cls._registered_classes
                    and cls._registered_classes[alias] != cls
                ):
                    raise ValueError(
                        f"Alias '{alias}' already registered to a different class"
                    )
                cls._registered_classes[alias] = cls

    @classmethod
    def from_serialized(cls: Type[T], data: Dict[str, Any]) -> T:
        """Create an instance from serialized data."""
        instance = cls.__new__(cls)
        Serializable.__init__(instance)
        instance.load_snapshot(data)
        return instance

    @classmethod
    def from_snapshot(cls: Type[T], data: Dict[str, Any]) -> T:
        """Create an instance from a snapshot."""
        instance = cls.__new__(cls)
        Serializable.__init__(instance)
        instance.load_snapshot(data)
        return instance

    def serialize(self) -> Dict[str, Any]:
        """Serialize the object to a dictionary."""
        return {"__class": self.__class__.__name__, "__value": self.create_snapshot()}

    @abstractmethod
    def create_snapshot(self) -> Dict[str, Any]:
        """Create a serializable snapshot of the object's state."""
        raise NotImplementedError

    @abstractmethod
    def load_snapshot(self, state: Dict[str, Any]) -> None:
        """Load object state from a snapshot."""
        raise NotImplementedError

    def clone(self: T) -> T:
        """Create a deep copy of the object."""
        snapshot = self.create_snapshot()
        return self.__class__.from_snapshot(deepcopy(snapshot))


# Example of how to use the base class:
class ExampleSerializable(Serializable):
    def __init__(self, data: str):
        super().__init__()
        self.data = data

    @classmethod
    def register(cls, aliases: Optional[list[str]] = None) -> None:
        """Register with custom aliases."""
        super().register(aliases)

    def create_snapshot(self) -> Dict[str, Any]:
        return {"data": self.data}

    def load_snapshot(self, state: Dict[str, Any]) -> None:
        self.data = state["data"]


# Usage example:
if __name__ == "__main__":
    # Register the class with an alias
    ExampleSerializable.register(aliases=["Example", "ExampleClass"])

    # Create and serialize an instance
    obj = ExampleSerializable("test data")
    serialized = obj.serialize()

    # Create new instance from serialized data
    new_obj = ExampleSerializable.from_serialized(serialized["__value"])

    # Create a clone
    cloned = obj.clone()

# bee_agent/memory/__init__.py
# ==================================================
from .message import BaseMessage, BaseMessageMeta
from .base_memory import BaseMemory
from .exceptions import MemoryError, MemoryFatalError
from .unconstrained_memory import UnconstrainedMemory
from .readonly_memory import ReadOnlyMemory
from .token_memory import TokenMemory

from .base_cache import BaseCache
from .file_cache import FileCache
from .sliding_cache import SlidingCache
from .unconstrained_cache import UnconstrainedCache

from .serializable import Serializable
from .serializer import Serializer
from .task_map import Task, SlidingTaskMap

__all__ = [
    "BaseMemory",
    "BaseMessageMeta",
    "UnconstrainedMemory",
    "ReadOnlyMemory",
    "TokenMemory",
    "MemoryError",
    "MemoryFatalError",
    "SummarizeMemory",
    "SlidingMemory",
    "BaseMessage",
    "BaseCache",
    "FileCache",
    "SlidingCache",
    "UnconstrainedCache",
    "Serializable",
    "Serializer",
    "Task",
    "SlidingTaskMap",
]

# bee_agent/memory/message.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC
from typing import Dict, Any, Optional, Type
from datetime import datetime
from copy import deepcopy
from dataclasses import dataclass

from bee_agent.utils import Role, RoleType


# Basic Serialization implementation
class Serializable(ABC):
    """Base class for serializable objects."""

    @classmethod
    def register(cls):
        # Registration logic would go here
        pass

    def serialize(self) -> Dict[str, Any]:
        """Serialize the object to a dictionary."""
        return self.create_snapshot()

    @classmethod
    def from_serialized(
        cls: Type["Serializable"], data: Dict[str, Any]
    ) -> "Serializable":
        """Create an instance from serialized data."""
        instance = cls.__new__(cls)
        instance.load_snapshot(data)
        return instance


# TypedDict equivalent for BaseMessageMeta
class BaseMessageMeta(Dict[str, Any]):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.created_at: Optional[datetime] = kwargs.get("created_at")


# Equivalent to TypeScript's BaseMessageInput interface
@dataclass
class BaseMessageInput:
    role: RoleType
    text: str
    meta: Optional[BaseMessageMeta] = None


@dataclass
class BaseMessage(Serializable):
    role: Role
    text: str
    meta: Optional[BaseMessageMeta] = None

    @classmethod
    def of(cls, data: Dict[str, str]) -> "BaseMessage":
        return cls(role=data["role"], text=data["text"])

    def __hash__(self):
        """Make BaseMessage hashable by using role and text."""
        return hash((self.role, self.text))

    def __eq__(self, other):
        """Define equality for BaseMessage."""
        if not isinstance(other, BaseMessage):
            return False
        return (
            self.role == other.role
            and self.text == other.text
            and self.meta == other.meta
        )

    def create_snapshot(self) -> Dict[str, Any]:
        """Create a serializable snapshot of the message."""
        return {"role": self.role, "text": self.text, "meta": deepcopy(self.meta)}

    def load_snapshot(self, state: Dict[str, Any]) -> None:
        """Load message state from a snapshot."""
        for key, value in state.items():
            setattr(self, key, value)
        return self

    @classmethod
    def register(cls):
        """Register the class for serialization."""
        super().register()


# Example usage:
if __name__ == "__main__":
    # Create a message using the of() factory method
    message = BaseMessage.of(
        {
            "role": Role.USER,
            "text": "Hello, how are you?",
            "meta": {"created_at": datetime.now()},
        }
    )
    message = BaseMessage.of(
        {
            "role": Role.USER,
            "text": "Hello, how are you?",
            "meta": {"created_at": datetime.now()},
        }
    )
    print(message)
    # Serialize the message
    serialized = message.serialize()
    print(serialized)
    # Create a new message from serialized data
    deserialized = BaseMessage.from_serialized(serialized)

# bee_agent/memory/base_cache.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod
from typing import Dict, Generic, Any, TypeVar


T = TypeVar("T")


class BaseCache(ABC, Generic[T]):
    """Abstract base class for all Cache implementations."""

    def __init__(self):
        """Initialize the cache with an empty elements dictionary."""
        self._elements: Dict[str, Any] = {}
        self._enabled: bool = True

    @property
    def enabled(self) -> bool:
        """
        Property that indicates if the cache is enabled.

        Returns:
            bool: True if cache is enabled, False otherwise
        """
        return self._enabled

    @enabled.setter
    def enabled(self, value: bool) -> None:
        """
        Set the enabled status of the cache.

        Args:
            value (bool): The new enabled status
        """
        self._enabled = value

    @property
    def elements(self) -> Dict[str, Any]:
        """
        Property that provides access to the internal elements dictionary.

        Returns:
            Dict[str, Any]: The cache elements
        """
        return self._elements

    async def serialize(self) -> str:
        """Serialize the cache state."""
        snapshot = await self.create_snapshot()
        from .serializer import Serializer  # Import here to avoid circular imports

        return await Serializer.serialize(
            {
                "target": {
                    "module": self.__class__.__module__,
                    "name": self.__class__.__name__,
                },
                "snapshot": snapshot,
            }
        )

    @abstractmethod
    async def set(self, key: str, value: Any) -> None:
        """Add a element in the cache."""
        pass

    @abstractmethod
    async def get(self, key: str) -> Any:
        """Get a element in the cache."""
        pass

    @abstractmethod
    async def has(self, key: str) -> bool:
        """Get a element in the cache."""
        pass

    @abstractmethod
    async def delete(self, key: str) -> bool:
        """Delete a element in the Cache."""
        pass

    @abstractmethod
    def clear(self) -> None:
        """Clear all the Cache content."""
        pass

    def size(self) -> int:
        """Clear all the Cache content."""
        return len(self.elements)

    def is_empty(self) -> bool:
        """Check if memory is empty."""
        return len(self.elements) == 0

    def __iter__(self):
        return iter(self.elements)

    @abstractmethod
    def create_snapshot(self) -> Any:
        """Create a serializable snapshot of current state."""
        pass

    @abstractmethod
    def load_snapshot(self, state: Any) -> None:
        """Restore state from a snapshot."""
        pass

# bee_agent/memory/serializer.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod
import json
from typing import Any, Dict, Type, TypeVar, Optional, Callable
import base64
from datetime import datetime
from .task_map import SlidingTaskMap, Task


T = TypeVar("T")


class SerializerError(Exception):
    """Custom error for serialization issues."""

    pass


class SerializerFactory:
    """Factory for serializable class registration and instantiation."""

    def __init__(self, cls_ref: Type[Any]):
        self.ref = cls_ref
        self.module = cls_ref.__module__
        self.name = cls_ref.__name__
        self.to_plain = None
        self.from_plain = None
        self.create_empty = None
        self.update_instance = None


class Serializable(ABC):
    """Base class for serializable objects."""

    @classmethod
    def register(cls) -> None:
        """Register for serialization."""
        Serializer.register_serializable(cls)

    @classmethod
    def from_snapshot(cls: Type[T], snapshot: Dict[str, Any]) -> T:
        """Create instance from snapshot."""
        instance = cls()
        instance.load_snapshot(snapshot)
        return instance

    @abstractmethod
    async def create_snapshot(self) -> Dict[str, Any]:
        """Create serializable snapshot."""
        pass

    @abstractmethod
    def load_snapshot(self, snapshot: Dict[str, Any]) -> None:
        """Restore from snapshot."""
        pass


class Serializer:
    """Main serializer class."""

    _factories: Dict[str, SerializerFactory] = {}

    @classmethod
    def register_serializable(cls, target_cls: Type[Any]) -> None:
        """Register a serializable class."""
        # Register with both module name and __main__
        names = [
            f"{target_cls.__module__}.{target_cls.__name__}",
            f"__main__.{target_cls.__name__}",
        ]
        factory = SerializerFactory(target_cls)
        factory.to_plain = lambda x: x.create_snapshot()
        factory.from_plain = target_cls.from_snapshot

        for name in names:
            cls._factories[name] = factory

    @classmethod
    def register(cls, target_cls: Type[Any], processors: Dict[str, Callable]):
        """Register a class with custom processors."""
        names = [
            f"{target_cls.__module__}.{target_cls.__name__}",
            f"__main__.{target_cls.__name__}",
        ]
        factory = SerializerFactory(target_cls)
        factory.to_plain = processors.get("to_plain")
        factory.from_plain = processors.get("from_plain")
        factory.create_empty = processors.get("create_empty")
        factory.update_instance = processors.get("update_instance")

        for name in names:
            cls._factories[name] = factory

    @classmethod
    def get_factory(cls, class_name: str) -> SerializerFactory:
        """Get factory for class name."""
        factory = cls._factories.get(class_name)
        if not factory:
            raise SerializerError(f"Class {class_name} not registered")
        return factory

    @classmethod
    async def serialize(cls, data: Any) -> str:
        """Serialize data to JSON string with async support."""

        async def serialize_obj(obj: Any) -> Any:
            if isinstance(obj, (str, int, float, bool)) or obj is None:
                return obj

            if isinstance(obj, (list, tuple)):
                return [await serialize_obj(item) for item in obj]

            if isinstance(obj, dict):
                return {str(k): await serialize_obj(v) for k, v in obj.items()}

            class_name = f"{obj.__class__.__module__}.{obj.__class__.__name__}"
            try:
                factory = cls.get_factory(class_name)
                if factory.to_plain:
                    snapshot = (
                        await obj.create_snapshot()
                        if hasattr(obj, "create_snapshot")
                        else factory.to_plain(obj)
                    )
                    return {
                        "__type": class_name,
                        "__value": await serialize_obj(snapshot),
                    }
            except SerializerError:
                pass

            raise SerializerError(f"Cannot serialize object of type {class_name}")

        serialized_data = await serialize_obj(data)
        return json.dumps(serialized_data)

    @classmethod
    async def deserialize(cls, data: str) -> Any:
        """Deserialize JSON string to object with async support."""

        async def deserialize_obj(obj: Any) -> Any:
            if isinstance(obj, (str, int, float, bool)) or obj is None:
                return obj

            if isinstance(obj, list):
                return [await deserialize_obj(item) for item in obj]

            if isinstance(obj, dict):
                if "__type" in obj:
                    factory = cls.get_factory(obj["__type"])
                    if factory.from_plain:
                        return factory.from_plain(await deserialize_obj(obj["__value"]))
                return {k: await deserialize_obj(v) for k, v in obj.items()}

            return obj

        return await deserialize_obj(json.loads(data))


# Register basic types
for type_cls in (list, dict, set):
    Serializer.register(
        type_cls,
        {
            "to_plain": lambda x: list(x) if isinstance(x, (list, set)) else dict(x),
            "from_plain": lambda x: type_cls(x),
        },
    )

Serializer.register(
    datetime,
    {
        "to_plain": lambda x: x.isoformat(),
        "from_plain": lambda x: datetime.fromisoformat(x),
    },
)

Serializer.register(
    bytes,
    {
        "to_plain": lambda x: base64.b64encode(x).decode("utf-8"),
        "from_plain": lambda x: base64.b64decode(x.encode("utf-8")),
    },
)

Serializer.register(
    SlidingTaskMap,
    {
        "to_plain": lambda value: {
            "config": {"size": value.size, "ttl": value.ttl},
            "entries": list(value.entries()),
        },
        "from_plain": lambda data: SlidingTaskMap.from_snapshot(data),
        "create_empty": lambda: SlidingTaskMap(size=1, ttl=1000),
        "update_instance": lambda instance, update: instance.load_snapshot(update),
    },
)

# Register Task for serialization
Serializer.register(
    Task,
    {
        "to_plain": lambda task: {
            "value": task.get_value() if task.is_resolved() else None,
            "state": task.get_state(),
        },
        "from_plain": lambda data: Task.from_snapshot(data),
        "create_empty": lambda: Task(),
        "update_instance": lambda instance, update: instance.load_snapshot(update),
    },
)

if __name__ == "__main__":
    import asyncio
    from typing import Optional

    class User(Serializable):
        def __init__(self, name: str = "", age: int = 0, email: Optional[str] = None):
            self.name = name
            self.age = age
            self.email = email

        async def create_snapshot(self) -> Dict[str, Any]:
            return {"name": self.name, "age": self.age, "email": self.email}

        def load_snapshot(self, snapshot: Dict[str, Any]) -> None:
            self.name = snapshot["name"]
            self.age = snapshot["age"]
            self.email = snapshot.get("email")

    # Register the class
    User.register()

    async def main():
        try:
            # Create and test serialization
            user = User("Alice", 30, "alice@example.com")

            print("\n1. Basic User Serialization:")
            serialized = await Serializer.serialize(user)
            print(f"Serialized User: {serialized}")

            deserialized = await Serializer.deserialize(serialized)
            print(f"Deserialized User: {deserialized.name}, {deserialized.age}")

            # Test with built-in types
            print("\n2. Built-in Types Serialization:")
            data = {"user": user, "numbers": [1, 2, 3], "timestamp": datetime.now()}

            serialized = await Serializer.serialize(data)
            print(f"Serialized Data: {serialized}")

            deserialized = await Serializer.deserialize(serialized)
            print(f"Deserialized Data (user name): {deserialized['user'].name}")

        except SerializerError as e:
            print(f"Serialization Error: {e}")
        except Exception as e:
            print(f"Unexpected Error: {str(e)}")

    # Run the async main function
    asyncio.run(main())

# bee_agent/memory/exceptions.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import List, Optional


class MemoryError(Exception):
    """Base class for memory-related exceptions."""

    pass


class MemoryFatalError(MemoryError):
    """Fatal memory errors that cannot be recovered from."""

    def __init__(
        self, message: str, errors: Optional[List[Exception]] = None, **kwargs
    ):
        super().__init__(message)
        self.errors = errors or []
        self.is_fatal = kwargs.get("is_fatal", True)
        self.is_retryable = kwargs.get("is_retryable", False)

# bee_agent/memory/summarize_memory.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import List, Optional, Dict, Iterable, TYPE_CHECKING

from .base_memory import BaseMemory
from .message import BaseMessage
from bee_agent.utils import Role


if TYPE_CHECKING:
    from bee_agent.llms import BaseLLM


class SummarizeMemory(BaseMemory):
    """Memory implementation that summarizes conversations."""

    def __init__(self, llm: "BaseLLM"):
        self._messages: List[BaseMessage] = []
        self.llm = llm

    @property
    def messages(self) -> List[BaseMessage]:
        return self._messages

    async def add(self, message: BaseMessage, index: Optional[int] = None) -> None:
        """Add a message and trigger summarization if needed."""
        messages_to_summarize = self._messages + [message]
        summary = self._summarize_messages(messages_to_summarize)

        self._messages = [BaseMessage(role=Role.SYSTEM, text=summary)]

    async def add_many(
        self, messages: Iterable[BaseMessage], start: Optional[int] = None
    ) -> None:
        """Add multiple messages and summarize."""
        messages_to_summarize = self._messages + list(messages)
        summary = self._summarize_messages(messages_to_summarize)

        self._messages = [BaseMessage(role=Role.SYSTEM, text=summary)]

    def _summarize_messages(self, messages: List[BaseMessage]) -> str:
        """Summarize a list of messages using the LLM."""
        if not messages:
            return ""

        prompt = {
            "prompt": """Summarize the following conversation. Be concise but include all key information.

Previous messages:
{}

Summary:""".format(
                "\n".join([f"{msg.role}: {msg.text}" for msg in messages])
            )
        }

        # Generate is synchronous, not async
        response = self.llm.generate(prompt)
        return response.output.response

    async def delete(self, message: BaseMessage) -> bool:
        """Delete a message from memory."""
        try:
            self._messages.remove(message)
            return True
        except ValueError:
            return False

    def reset(self) -> None:
        """Clear all messages from memory."""
        self._messages.clear()

    def create_snapshot(self) -> Dict:
        """Create a serializable snapshot of current state."""
        return {"messages": self._messages.copy()}

    def load_snapshot(self, state: Dict) -> None:
        """Restore state from a snapshot."""
        self._messages = state["messages"].copy()

# bee_agent/memory/task_map.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import Any, Dict, Generic, List, TypeVar, Optional
import time
from collections import OrderedDict

K = TypeVar("K")
V = TypeVar("V")


class Task:
    def __init__(self):
        self._value = None
        self._state = "pending"
        self._resolved = False

    def resolve(self, value: Any) -> None:
        self._value = value
        self._state = "resolved"
        self._resolved = True

    def get_value(self) -> Any:
        return self._value

    def get_state(self) -> str:
        return self._state

    def is_resolved(self) -> bool:
        return self._resolved

    @classmethod
    def from_snapshot(cls, snapshot: Dict[str, Any]) -> "Task":
        """Create instance from snapshot data."""
        task = cls()
        if snapshot["state"] == "resolved":
            task.resolve(snapshot["value"])
        return task

    def load_snapshot(self, snapshot: Dict[str, Any]) -> None:
        """Load state from snapshot data."""
        if snapshot["state"] == "resolved":
            self.resolve(snapshot["value"])


class SlidingTaskMap(Generic[K, V]):
    """
    A size-limited map that evicts oldest entries when full.
    Optionally supports TTL-based eviction.
    """

    def __init__(self, size: float, ttl: Optional[float] = None):
        """
        Initialize the sliding map.

        Args:
            size: Maximum number of items to store
            ttl: Time-to-live in seconds for entries (optional)
        """
        self._max_size = size
        self._ttl = ttl
        self._items: OrderedDict[K, tuple[V, float]] = OrderedDict()

    def _evict_expired(self) -> None:
        """Remove expired entries based on TTL."""
        if self._ttl is None:
            return

        current_time = time.time()
        expired_keys = [
            key
            for key, (_, timestamp) in self._items.items()
            if current_time - timestamp > self._ttl
        ]

        for key in expired_keys:
            self.delete(key)

    def get(self, key: K) -> Optional[V]:
        """Get a value by key, handling expiration."""
        self._evict_expired()
        if key in self._items:
            value, _ = self._items[key]
            # Move to end to mark as recently used
            self._items.move_to_end(key)
            return value
        return None

    def set(self, key: K, value: V) -> None:
        """Set a value, handling size limits."""
        self._evict_expired()

        # If we're at max size and this is a new key, remove oldest
        if len(self._items) >= self._max_size and key not in self._items:
            self._items.popitem(last=False)

        self._items[key] = (value, time.time())
        self._items.move_to_end(key)

    def has(self, key: K) -> bool:
        """Check if a key exists and hasn't expired."""
        self._evict_expired()
        return key in self._items

    def delete(self, key: K) -> bool:
        """Delete a key, returning True if it existed."""
        if key in self._items:
            value, _ = self._items.pop(key)
            if isinstance(value, Task):
                value.destructor()
            return True
        return False

    def clear(self) -> None:
        """Remove all items."""
        for key in list(self._items.keys()):
            self.delete(key)

    @property
    def size(self) -> int:
        """Get current number of items."""
        self._evict_expired()
        return len(self._items)

    @property
    def ttl(self) -> Optional[float]:
        """Get the TTL value."""
        return self._ttl

    def entries(self) -> List[tuple[K, V]]:
        """Get all entries for serialization."""
        return [(k, v[0]) for k, v in self._items.items()]

    @classmethod
    def from_snapshot(cls, snapshot: Dict[str, Any]) -> "SlidingTaskMap":
        """Create instance from snapshot data."""
        instance = cls(size=snapshot["config"]["size"], ttl=snapshot["config"]["ttl"])
        for key, value in snapshot["entries"]:
            instance.set(key, value)
        return instance

    def load_snapshot(self, snapshot: Dict[str, Any]) -> None:
        """Load state from snapshot data."""
        self._size = snapshot["config"]["size"]
        self._ttl = snapshot["config"]["ttl"]
        self._items.clear()
        current_time = time.time()
        for key, value in snapshot["entries"]:
            self._items[key] = (value, current_time)

# bee_agent/memory/unconstrained_cache.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import TypeVar, Dict, Any, Generic
from .base_cache import BaseCache
from .serializer import Serializer

T = TypeVar("T")


class UnconstrainedCache(BaseCache[T], Generic[T]):
    """Cache implementation without size or time constraints."""

    def __init__(self):
        """Initialize the unconstrained cache."""
        super().__init__()
        self._provider: Dict[str, T] = {}
        self._register()

    @classmethod
    def _register(cls) -> None:
        """Register for serialization."""
        Serializer.register(
            cls,
            {
                "to_plain": lambda x: {
                    "enabled": x.enabled,
                    "provider": dict(x._provider),
                },
                "from_plain": lambda x: cls.from_snapshot(x),
            },
        )

    async def get(self, key: str) -> T:
        """Get a value from the cache."""
        return self._provider.get(key)

    async def has(self, key: str) -> bool:
        """Check if a key exists in the cache."""
        return key in self._provider

    async def clear(self) -> None:
        """Clear all items from the cache."""
        self._provider.clear()

    async def delete(self, key: str) -> bool:
        """Delete a key from the cache."""
        if key in self._provider:
            del self._provider[key]
            return True
        return False

    async def set(self, key: str, value: T) -> None:
        """Set a value in the cache."""
        self._provider[key] = value

    async def size(self) -> int:
        """Get the current number of items in the cache."""
        return len(self._provider)

    async def create_snapshot(self) -> Dict[str, Any]:
        """Create a serializable snapshot of the current state."""
        return {"enabled": self.enabled, "provider": dict(self._provider)}

    def load_snapshot(self, snapshot: Dict[str, Any]) -> None:
        """Restore state from a snapshot."""
        self._enabled = snapshot["enabled"]
        self._provider = dict(snapshot["provider"])

    @classmethod
    def from_snapshot(cls, snapshot: Dict[str, Any]) -> "UnconstrainedCache[T]":
        """Create an instance from a snapshot."""
        instance = cls()
        instance.load_snapshot(snapshot)
        return instance


if __name__ == "__main__":
    import asyncio

    async def test_unconstrained_cache():
        try:
            print("\n1. Testing Basic Operations:")
            # Create cache instance
            cache = UnconstrainedCache[str]()

            # Test setting and getting values
            print("Setting test values...")
            await cache.set("key1", "value1")
            await cache.set("key2", "value2")
            await cache.set("key3", "value3")

            # Test retrieval
            value1 = await cache.get("key1")
            value2 = await cache.get("key2")
            print(f"Retrieved values: key1={value1}, key2={value2}")

            # Test has method
            exists = await cache.has("key1")
            not_exists = await cache.has("nonexistent")
            print(f"Has key1: {exists}")
            print(f"Has nonexistent: {not_exists}")

            # Test size
            size = await cache.size()
            print(f"Cache size: {size}")

            print("\n2. Testing Delete Operation:")
            # Test deletion
            deleted = await cache.delete("key2")
            size_after_delete = await cache.size()
            print(f"Deleted key2: {deleted}")
            print(f"Size after delete: {size_after_delete}")

            print("\n3. Testing Clear Operation:")
            # Test clear
            await cache.clear()
            size_after_clear = await cache.size()
            print(f"Size after clear: {size_after_clear}")

            print("\n4. Testing Serialization:")
            # Test serialization
            new_cache = UnconstrainedCache[str]()
            await new_cache.set("test1", "data1")
            await new_cache.set("test2", "data2")

            # Create snapshot
            snapshot = await new_cache.create_snapshot()
            print(f"Created snapshot: {snapshot}")

            # Create new instance from snapshot
            restored_cache = UnconstrainedCache.from_snapshot(snapshot)
            restored_value = await restored_cache.get("test1")
            print(f"Restored value from snapshot: {restored_value}")

            print("\n5. Testing Enabled Property:")
            # Test enabled property
            original_state = new_cache.enabled
            new_cache.enabled = False
            print(f"Original enabled state: {original_state}")
            print(f"New enabled state: {new_cache.enabled}")

            print("\n6. Testing Large Dataset:")
            # Test with larger dataset
            large_cache = UnconstrainedCache[int]()
            print("Adding 1000 items...")
            for i in range(1000):
                await large_cache.set(f"key{i}", i)

            large_size = await large_cache.size()
            sample_value = await large_cache.get("key500")
            print(f"Large cache size: {large_size}")
            print(f"Sample value (key500): {sample_value}")

            print("\nAll tests completed successfully!")

        except Exception as e:
            print(f"Error during test: {str(e)}")

    # Run the tests
    asyncio.run(test_unconstrained_cache())

# bee_agent/agents/runner.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod


class BaseRunner(ABC):
    _llm = None
    tools = []
    iterations = []

    def __init__(self, llm, tools=[], options=None):
        self._llm = llm
        self.tools = tools

    @abstractmethod
    def init_memory(self, input):
        pass

    @abstractmethod
    def iterate(self):
        pass

    def start_iteration(self):
        pass

# bee_agent/agents/__init__.py
# ==================================================
from .agent import BaseAgent, BeeAgent


__all__ = ["BaseAgent", "BeeAgent"]

# bee_agent/agents/agent.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

import asyncio
import json

from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Any, Dict, List, Optional, TypeVar, Union


from bee_agent.llms import (
    BaseLLM,
    Prompt,
    AssistantPromptTemplate,
    SystemPromptTemplate,
    UserPromptTemplate,
)
from bee_agent.memory import BaseMessage, BaseMemory, UnconstrainedMemory
from bee_agent.tools import Tool
from bee_agent.utils import BeeLogger, BeeEventEmitter, MessageEvent, Role


logger = BeeLogger(__name__)
event_emitter = BeeEventEmitter()
T = TypeVar("T")


class BaseAgent(ABC):
    llm: Optional[BaseLLM] = None
    tools: List[Tool]
    memory: BaseMemory

    max_iterations = 20

    @property
    def __is_loop_running(self) -> bool:
        try:
            asyncio.get_running_loop()
            return True
        except RuntimeError:
            return False

    def __init__(
        self,
        llm: Optional[BaseLLM] = None,
        tools: Optional[List[Tool]] = [],
        memory: Optional[BaseMemory] = None,
    ):
        self.llm = llm
        self.tools = tools
        self.memory = memory if memory else UnconstrainedMemory()

        logger.debug(f"Using model {self.llm.model}")

    @abstractmethod
    def _run(self, prompt: Optional[Prompt] = None, options: Optional[T] = None):
        pass

    async def init_memory(self):
        logger.debug(f"Initializing {type(self.memory).__name__}")

        self.memory.reset()
        system_prompt_data = {}

        if len(self.tools):
            tool_box = [tool.prompt_data() for tool in self.tools]
            system_prompt_data = {
                "tools": tool_box,
                "tools_length": len(tool_box),
                "instructions": "You are a helpful assistant",
            }

        await self.memory.add(
            BaseMessage.of(
                {
                    "role": Role.SYSTEM,
                    "text": SystemPromptTemplate.render(system_prompt_data),
                    "meta": {"createdAt": datetime.now().isoformat()},
                }
            )
        )

    async def plan_step(self, prompt, step_state={}, options=None):
        iteration_count = step_state.get("count", 0)

        logger.debug(f"Preparing for iteration: {iteration_count + 1}")

        if iteration_count >= self.max_iterations:
            logger.warning("Maximum iterations reached. Stopping.")
            return

        if iteration_count == 0:
            user_prompt_text = UserPromptTemplate.render(
                {"input": prompt.get("prompt", "")}
            )

            event_emitter.emit(
                MessageEvent(source=Role.USER, message=prompt.get("prompt", ""))
            )

            await self.memory.add(
                BaseMessage.of(
                    {
                        "role": Role.USER,
                        "text": user_prompt_text,
                        "meta": {"createdAt": datetime.now().isoformat()},
                    }
                )
            )

        step_state["count"] = iteration_count + 1

        output_parts = step_state.pop("output_parts", {})
        if output_parts.get("Function Name") and output_parts.get("Function Input"):
            tool_input = json.loads(output_parts.get("Function Input"))
            tool_name = output_parts.get("Function Name")

            tool = list(filter(lambda t: t.name == tool_name, self.tools))[0]

            tool_response = tool.run(tool_input)
            logger.debug(f"Response from {tool_name}: {tool_response}")

            assistant_prompt_text = AssistantPromptTemplate.render(
                {
                    "thought": output_parts.get("Thought"),
                    "tool_name": output_parts.get("Function Name"),
                    "tool_input": tool_input,
                    "tool_output": tool_response,
                }
            )

            event_emitter.emit_many(
                [
                    MessageEvent(
                        source="Agent",
                        state="thought",
                        message=output_parts.get("Thought"),
                    ),
                    MessageEvent(
                        source="Agent",
                        state="tool_name",
                        message=output_parts.get("Function Name"),
                    ),
                    MessageEvent(
                        source="Agent",
                        state="tool_input",
                        message=output_parts.get("Function Input"),
                    ),
                ]
            )

            await self.memory.add(
                BaseMessage.of(
                    {
                        "role": Role.ASSISTANT,
                        "text": assistant_prompt_text,
                        "meta": {"createdAt": datetime.now().isoformat()},
                    }
                )
            )

        await self.execute_step(prompt, step_state, options)

    async def execute_step(self, prompt, step_state={}, options=None):
        logger.debug(f"Running iteration: {step_state.get('count')}")

        response = self._run(prompt, options)
        await self.observe_step(response, prompt, step_state, options)

    async def observe_step(self, output, prompt, step_state, options):
        logger.debug(f"Reviewing result of iteration: {step_state.get('count')}")

        content = (
            output if type(output) is str else output.messages[0]
        )  # output.get("message", {}).get("content")
        result = self.llm.parse_output(content, self.tools) if self.llm else content

        if result:
            output_parts = {}
            for line in result.split("\n"):
                if ":" in line:
                    k, v = line.split(":", 1)
                    output_parts[k.strip()] = v.strip()

            final_answer = output_parts.get("Final Answer")
            if final_answer:
                event_emitter.emit(
                    MessageEvent(
                        source="Agent", message=final_answer, state="final_answer"
                    )
                )

                await self.memory.add(
                    BaseMessage.of(
                        {
                            "role": Role.ASSISTANT,
                            "text": final_answer,
                            "meta": {"createdAt": datetime.now().isoformat()},
                        }
                    )
                )
            else:
                step_state["output_parts"] = output_parts
                await self.plan_step(prompt, step_state, options)
        else:
            await self.plan_step(prompt, step_state, options)

    def run(
        self, prompt: Optional[Union[Prompt, str]] = None, options: Optional[T] = None
    ):
        _prompt = {"prompt": prompt} if type(prompt) is str else prompt

        async def runner(agent, _prompt):
            await agent.init_memory()
            await agent.plan_step(_prompt, {"count": 0}, options)

        if self.__is_loop_running:
            # Create a separate thread so we can block before returning
            with ThreadPoolExecutor(1) as pool:
                pool.submit(lambda: asyncio.run(runner(self, _prompt))).result()
        else:
            # No event loop
            asyncio.run(runner(self, _prompt))


class BeeAgent(BaseAgent):
    def _run(self, prompt: Prompt, options: Optional[Dict[str, Any]] = None):
        if self.llm:
            return self.llm.generate(self.memory.messages, options)

# bee_agent/utils/config.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        env_nested_delimiter="__",
        env_prefix="bee_",
        extra="ignore",
    )

    log_level: str = "INFO"


CONFIG = Settings()

# bee_agent/utils/roles.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from enum import Enum
from typing import Union


RoleType = Union[str, None]  # Equivalent to TypeScript's string type for roles


# Basic Role class
class Role(str, Enum):
    ASSISTANT: str = "assistant"
    SYSTEM: str = "system"
    USER: str = "user"

    @classmethod
    def values(cls) -> set[str]:
        return {
            value
            for key, value in vars(cls).items()
            if not key.startswith("_") and isinstance(value, str)
        }

# bee_agent/utils/events.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

import asyncio

from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from typing import Any, List, Literal, Optional

from pyventus import AsyncIOEventEmitter, EmittableEventType, EventEmitter


@dataclass
class MessageEvent:
    source: Literal["User", "Agent"]
    message: str
    state: Optional[str] = None


class BeeEventEmitter(AsyncIOEventEmitter):
    @property
    def __is_loop_running(self) -> bool:
        try:
            asyncio.get_running_loop()
            return True
        except RuntimeError:
            return False

    def _process(self, event_emission: EventEmitter.EventEmission) -> None:
        # Check if there is an active event loop
        is_loop_running: bool = self.__is_loop_running

        # Log the execution context, if debug mode is enabled
        if self._logger.debug_enabled:  # pragma: no cover
            self._logger.debug(
                action="Context:", msg=f"{'Async' if is_loop_running else 'Sync'}"
            )

        if is_loop_running:
            # Create a separate thread
            with ThreadPoolExecutor(1) as pool:
                pool.submit(lambda: asyncio.run(event_emission())).result()

        else:
            # Run the event emission in a blocking manner
            asyncio.run(event_emission())

    def emit_many(self, /, events: List[EmittableEventType], *args: Any, **kwargs: Any):
        for event in events:
            self.emit(event, *args, **kwargs)

# bee_agent/utils/__init__.py
# ==================================================
from .config import CONFIG
from .custom_logger import BeeLogger
from .events import BeeEventEmitter, MessageEvent
from .roles import Role, RoleType


__all__ = ["CONFIG", "BeeEventEmitter", "BeeLogger", "MessageEvent", "Role", "RoleType"]

# bee_agent/utils/custom_logger.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

import logging
import sys

from pyventus import EventHandler, EventLinker

from .config import CONFIG
from .events import MessageEvent
from .roles import Role


_handler: EventHandler = None


class BeeLoggerFormatter:
    def format(self, record: logging.LogRecord):
        if hasattr(record, "is_event_message") and record.is_event_message:
            return logging.Formatter(
                "{asctime} {levelname:<8s} - {message}",
                style="{",
                datefmt="%Y-%m-%d %H:%M:%S",
            ).format(record)
        else:
            return logging.Formatter(
                "{asctime} {levelname:<8s} {name} - {message}",
                style="{",
                datefmt="%Y-%m-%d %H:%M:%S",
            ).format(record)


class BeeLogger(logging.Logger):

    def __init__(self, name, level=CONFIG.log_level):
        super().__init__(name, level)

        console_handler = logging.StreamHandler(stream=sys.stdout)
        console_handler.setFormatter(BeeLoggerFormatter())

        self.addHandler(console_handler)

        global _handler
        if _handler is None:
            _handler = EventLinker.subscribe(
                MessageEvent, event_callback=self.log_message_events
            )

    def log_message_events(self, event: MessageEvent):
        source = str.lower(event.source)
        state = f" ({event.state})" if event.state else ""
        icon = " ðŸ‘¤" if source == str.lower(Role.USER) else " ðŸ¤–"
        self.info(
            f" {str.capitalize(source)}{state}{icon}: {event.message}",
            extra={"is_event_message": True},
        )

# bee_agent/llms/__init__.py
# ==================================================
from .base_output import BaseChatLLMOutput, BaseLLMOutput
from .llm import BaseLLM, LLM, AgentInput
from .prompt import (
    Prompt,
    AssistantPromptTemplate,
    SystemPromptTemplate,
    UserPromptTemplate,
)
from .output import ChatLLMOutput, ChatOutput

__all__ = [
    "BaseLLM",
    "LLM",
    "BaseChatLLMOutput",
    "BaseLLMOutput",
    "Prompt",
    "ChatLLMOutput",
    "ChatOutput",
    "AgentInput",
    "AssistantPromptTemplate",
    "SystemPromptTemplate",
    "UserPromptTemplate",
]

# bee_agent/llms/llm.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, TypeVar, Generic, Union
from dataclasses import dataclass
import re

from litellm import completion
import math


from .base_output import BaseChatLLMOutput
from .output import ChatLLMOutput, ChatOutput
from .prompt import Prompt
from bee_agent.memory.base_memory import BaseMemory, BaseMessage
from bee_agent.utils.custom_logger import BeeLogger
from bee_agent.utils.roles import Role


T = TypeVar("T", bound="BaseChatLLMOutput")
logger = BeeLogger(__name__)


class BaseLLM(Generic[T], ABC):
    """Abstract base class for Language Model implementations."""

    base_url: Optional[str]
    model: Optional[str]

    def __init__(self, base_url: Optional[str] = None, model: Optional[str] = None):
        self.base_url = base_url

        if "/" not in model:
            self.model = f"ollama_chat/{model}"
        else:
            self.model = (
                model
                if not model.startswith("ollama/")
                else f"{model.replace('ollama/', 'ollama_chat/')}"
            )

    @abstractmethod
    def inference(self, input: List[BaseMessage], options: Any) -> T:
        pass

    @abstractmethod
    def parse_output(self, output, tools):
        pass

    def generate(self, prompt: Union[Prompt, List[BaseMessage]], options=None) -> T:
        if type(prompt) is dict:
            input = [BaseMessage.of({"role": Role.USER, "text": prompt.get("prompt")})]
        else:
            input = prompt

        answer = self.inference(input, options)
        return answer

    @abstractmethod
    def tokenize(self, input: str) -> T:
        pass


class LLM(BaseLLM[BaseChatLLMOutput]):
    parameters: Dict[str, Any] = {}
    chat_endpoint = "/api/chat"

    def __init__(
        self,
        model: str = "ollama_chat/llama3.1",
        base_url: str = "http://localhost:11434",
        parameters: Dict[str, Any] = {},
    ):
        h = base_url[:-1] if base_url.endswith("/") else base_url
        self.parameters = {
            "temperature": 0,
            "repeat_penalty": 1.0,
            "num_predict": 2048,
        } | parameters

        super().__init__(h, model)

    def prepare_messages(self, input: List[BaseMessage]):
        return list(map(lambda x: {"role": x.role, "content": x.text}, input))

    def inference(self, input: List[BaseMessage], options=None) -> BaseChatLLMOutput:
        response = completion(
            model=self.model,
            messages=self.prepare_messages(input),
        )

        logger.debug(f"Inference response choices size: {len(response.choices)}")
        response_content = (
            response.get("choices", [{}])[0].get("message", {}).get("content", "")
        )
        logger.debug(f"Inference response content:\n{response_content}")

        return ChatLLMOutput(output=ChatOutput(response=response_content))

    def tokenize(self, input: str) -> T:
        return {"tokens_count": math.ceil(len(input) / 4)}

    def parse_output(self, output, tools):
        if len(tools):
            regex = (
                r"Thought: .+\n+(?:Final Answer: [\s\S]+|Function Name: ("
                + "|".join(list(map(lambda x: x.name, tools)))
                + ")\n+Function Input: \\{.*\\}(\n+Function Output:)?)"
            )
        else:
            regex = r"Thought: .+\n+Final Answer: [\s\S]+"
        r = re.search(regex, output.text)
        if r is not None:
            return r.group()


@dataclass
class AgentInput(Generic[T]):
    """Input configuration for agent initialization."""

    llm: BaseLLM[T]
    memory: "BaseMemory"

# bee_agent/llms/prompt.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from typing import Any, Optional, TypedDict

import chevron


class Prompt(TypedDict):
    prompt: Optional[str]


class PromptTemplate:
    template: str

    def __init__(self, template: str):
        self.template = template

    def render(self, data: dict[str, Any] = {}):
        return chevron.render(template=self.template, data=data)


UserPromptTemplate = PromptTemplate("Message: {{input}}")


AssistantPromptTemplate = PromptTemplate(
    "{{#thought}}Thought: {{.}}\n{{/thought}}{{#tool_name}}Function Name: {{.}}\n{{/tool_name}}{{#tool_input}}Function Input: {{.}}\n{{/tool_input}}{{#toolOutput}}Function Output: {{.}}\n{{/toolOutput}}{{#final_answer}}Final Answer: {{.}}{{/final_answer}}"
)


SystemPromptTemplate = PromptTemplate(
    """# Available functions
{{#tools_length}}
You can only use the following functions. Always use all required parameters.

{{#tools}}
Function Name: {{name}}
Description: {{description}}
Parameters: {{&schema}}

{{/tools}}
{{/tools_length}}
{{^tools_length}}
No functions are available.

{{/tools_length}}
# Communication structure
You communicate only in instruction lines. The format is: "Instruction: expected output". You must only use these instruction lines and must not enter empty lines or anything else between instruction lines.
{{#tools_length}}
You must skip the instruction lines Function Name, Function Input and Function Output if no function calling is required.
{{/tools_length}}

Message: User's message. You never use this instruction line.
{{^tools_length}}
Thought: A single-line plan of how to answer the user's message. It must be immediately followed by Final Answer.
{{/tools_length}}
{{#tools_length}}
Thought: A single-line step-by-step plan of how to answer the user's message. You can use the available functions defined above. This instruction line must be immediately followed by Function Name if one of the available functions defined above needs to be called, or by Final Answer. Do not provide the answer here.
Function Name: Name of the function. This instruction line must be immediately followed by Function Input.
Function Input: Function parameters. Empty object is a valid parameter.
Function Output: Output of the function in JSON format.
Thought: Continue your thinking process.
{{/tools_length}}
Final Answer: Answer the user or ask for more information or clarification. It must always be preceded by Thought.

## Examples
Message: Can you translate "How are you" into French?
Thought: The user wants to translate a text into French. I can do that.
Final Answer: Comment vas-tu?

# Instructions
User can only see the Final Answer, all answers must be provided there.
{{^tools_length}}
You must always use the communication structure and instructions defined above. Do not forget that Thought must be a single-line immediately followed by Final Answer.
{{/tools_length}}
{{#tools_length}}
You must always use the communication structure and instructions defined above. Do not forget that Thought must be a single-line immediately followed by either Function Name or Final Answer.
Functions must be used to retrieve factual or historical information to answer the message.
{{/tools_length}}
If the user suggests using a function that is not available, answer that the function is not available. You can suggest alternatives if appropriate.
When the message is unclear or you need more information from the user, ask in Final Answer.

# Your capabilities
Prefer to use these capabilities over functions.
- You understand these languages: English, Spanish, French.
- You can translate and summarize, even long documents.

# Notes
- If you don't know the answer, say that you don't know.
- The current time and date in ISO format can be found in the last message.
- When answering the user, use friendly formats for time and date.
- Use markdown syntax for formatting code snippets, links, JSON, tables, images, files.
- Sometimes, things don't go as planned. Functions may not provide useful information on the first few tries. You should always try a few different approaches before declaring the problem unsolvable.
- When the function doesn't give you what you were asking for, you must either use another function or a different function input.
  - When using search engines, you try different formulations of the query, possibly even in a different language.
- You cannot do complex calculations, computations, or data manipulations without using functions.

# Role
{{instructions}}"""
)

# bee_agent/llms/output.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from dataclasses import dataclass
from typing import Sequence, List

from .base_output import BaseChatLLMOutput
from bee_agent.memory.message import BaseMessage
from bee_agent.utils import Role


@dataclass
class ChatOutput:
    """Represents a chat output from Ollama LLM."""

    response: str

    def to_messages(self) -> List[BaseMessage]:
        """Convert the response to a list of messages."""
        return [BaseMessage(role=Role.ASSISTANT, text=self.response)]


@dataclass
class ChatLLMOutput(BaseChatLLMOutput):
    """Concrete implementation of ChatLLMOutput for Ollama."""

    output: ChatOutput

    @property
    def messages(self) -> Sequence[BaseMessage]:
        return self.output.to_messages()

# bee_agent/llms/base_output.py
# ==================================================
# SPDX-License-Identifier: Apache-2.0

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Sequence
from bee_agent.memory.message import BaseMessage


@dataclass
class BaseLLMOutput:
    """Base class for LLM outputs."""

    pass


class BaseChatLLMOutput(BaseLLMOutput, ABC):
    """Abstract base class for chat LLM outputs."""

    @property
    @abstractmethod
    def messages(self) -> Sequence[BaseMessage]:
        """Get the messages from the LLM output.
        Returns:
            Sequence[BaseMessage]: A read-only sequence of messages
        """
        raise NotImplementedError
